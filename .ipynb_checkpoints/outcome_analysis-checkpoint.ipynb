{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from lime import submodular_pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/bank.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c9c055a447df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read original data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'bank.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/bank.csv'"
     ]
    }
   ],
   "source": [
    "# read original data\n",
    "path = '../data/'\n",
    "data_df = pd.read_csv(path+'bank.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop duration\n",
    "data_df.pop(\"duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process day of month\n",
    "\n",
    "#start = beginning of the month\n",
    "#middle = middle of the month\n",
    "#end = end of the month\n",
    "\n",
    "temp_day = []\n",
    "for i in data_df['day']:\n",
    "    if i<8:\n",
    "        temp_day.append(\"start\")\n",
    "    elif i>23:\n",
    "        temp_day.append(\"end\")\n",
    "    else:\n",
    "        temp_day.append(\"middle\")\n",
    "\n",
    "data_df['day'] = temp_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Definedata():\n",
    "    # define dataset\n",
    "    X=data.values\n",
    "    y=labels\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Models(models, X_train, X_test, y_train, y_test, title):\n",
    "    model = models\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    X, y = Definedata()\n",
    "    train_matrix = pd.crosstab(y_train, model.predict(X_train), rownames=['Actual'], colnames=['Predicted'])    \n",
    "    test_matrix = pd.crosstab(y_test, model.predict(X_test), rownames=['Actual'], colnames=['Predicted'])\n",
    "    matrix = pd.crosstab(y, model.predict(X), rownames=['Actual'], colnames=['Predicted'])\n",
    "    \n",
    "    f,(ax1,ax2,ax3) = plt.subplots(1,3,sharey=True, figsize=(20, 3))\n",
    "    #f = plt.figure(figsize=(20, 3))\n",
    "    \n",
    "    g1 = sns.heatmap(train_matrix, annot=True, fmt=\".1f\", cbar=False,ax=ax1)\n",
    "    g1.set_title(title)\n",
    "    g1.set_ylabel('Total Deposit = {}'.format(y_train.sum()), fontsize=14, rotation=90)\n",
    "    g1.set_xlabel('Accuracy score for Training Dataset = {}'.format(accuracy_score(model.predict(X_train), y_train)))\n",
    "    g2 = sns.heatmap(test_matrix, annot=True, fmt=\".1f\",cbar=False,ax=ax2)\n",
    "    g2.set_title(title)\n",
    "    g2.set_ylabel('Total Deposit = {}'.format(y_test.sum()), fontsize=14, rotation=90)\n",
    "    g2.set_xlabel('Accuracy score for Testing Dataset = {}'.format(accuracy_score(model.predict(X_test), y_test)))\n",
    "    g3 = sns.heatmap(matrix, annot=True, fmt=\".1f\",cbar=False,ax=ax3)\n",
    "    g3.set_title(title)\n",
    "    g3.set_ylabel('Total Deposit = {}'.format(y.sum()), fontsize=14, rotation=90)\n",
    "    g3.set_xlabel('Accuracy score for Total Dataset = {}'.format(accuracy_score(model.predict(X), y)))\n",
    "    \n",
    "    plt.show()\n",
    "    return y, model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def Featureimportances(models, X_train, y_train):\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train,y_train)\n",
    "    importances = model.feature_importances_\n",
    "    features = data.columns\n",
    "    if len(importances)<len(features): \n",
    "        features = data.columns[:len(importances)]\n",
    "    else:\n",
    "        importances = model.feature_importances_[:len(features)]\n",
    "    imp = pd.DataFrame({'Features': features, 'Importance': importances})\n",
    "    imp = imp.sort_values(by = 'Importance', ascending=False)[:15]\n",
    "    imp['Sum Importance'] = imp['Importance'].cumsum()\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(x=imp.Features,y=imp.Importance, marker=dict(color=list(range(20)), colorscale=\"Sunsetdark\")))\n",
    "\n",
    "    fig.update_layout(title=\"Feature Importance\",\n",
    "                                 xaxis_title=\"Features\", yaxis_title=\"Importance\",title_x=0.5, paper_bgcolor=\"mintcream\",\n",
    "                                 title_font_size=20)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of feature names (excluding the outcome variable)\n",
    "feature_names = data_df.columns[:-1]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark labels and encode them using sklearn\n",
    "labels = data_df.iloc[:,-1]\n",
    "le= sklearn.preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)\n",
    "class_names = le.classes_\n",
    "data = data_df.iloc[:,:-1]\n",
    "le_label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Class names: \", class_names)\n",
    "print(\"Label mapping: \", le_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are categorical varibles that we need to make dummies for\n",
    "print(data.dtypes)\n",
    "# Get a list of which variables are categorical\n",
    "categorical_features  = [i for i in range(len(data.dtypes)) if data.dtypes[i]=='object']\n",
    "print(\"Indices of categorical features: \", categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode categorical features\n",
    "categorical_names = {}\n",
    "for feature in categorical_features:\n",
    "    print(\"Feature: \", feature)\n",
    "    # Use label encoder to map categories to numbers\n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    le.fit(data.iloc[:, feature])\n",
    "    # Replace the categories with corresponding numbers in the original data\n",
    "    data.iloc[:, feature] = le.transform(data.iloc[:, feature])\n",
    "    # Store and print the mappings for reference later\n",
    "    categorical_names[feature] = le.classes_\n",
    "    print(categorical_names[feature])\n",
    "    print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This variable is where we store the original names of each category for each variable\n",
    "categorical_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(data, labels, test_size=0.33, random_state=2)\n",
    "print(\"Train shape: \", train.shape)\n",
    "print(\"Test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions \n",
    "pred_labels_test = rf.predict(test)\n",
    "\n",
    "# Calcualte accuracy on the test set\n",
    "print(\"Test set accuracy: \", sklearn.metrics.accuracy_score(labels_test, pred_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,auc,roc_curve\n",
    "\n",
    "title = 'RandomForestClassifier'\n",
    "y, ypred =  Models(RandomForestClassifier(), train, test, labels_train, labels_test, title)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y, ypred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',label='AUC = %0.3f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize explaner\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(train.values, \n",
    "                                                   feature_names=feature_names,\n",
    "                                                   class_names=class_names,\n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   categorical_names=categorical_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: rf.predict_proba(x).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose one example\n",
    "i = 0\n",
    "print('Actual class: ', labels_test[i])\n",
    "# Get explanation\n",
    "exp = explainer.explain_instance((test.values[i]), predict_fn, num_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the explanation \n",
    "%matplotlib inline\n",
    "fig = exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show another way\n",
    "exp.show_in_notebook(show_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SP object\n",
    "sp_obj = submodular_pick.SubmodularPick(explainer, train.values, predict_fn, sample_size=10, \n",
    "                                        num_features=5, num_exps_desired=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples selected\n",
    "sp_obj.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ind in sp_obj.V:\n",
    "    exp = explainer.explain_instance(test.values[ind], predict_fn, num_features=5)\n",
    "    print(\"Actual class: \", labels_test[ind])\n",
    "    exp.show_in_notebook(show_all=False)\n",
    "    print(\"==========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Featureimportances(RandomForestClassifier(), train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disparate Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train\n",
    "\n",
    "#create middle age column\n",
    "train_df['middle_age'] = [1 if (30 <= i <= 50) else 0 for i in train_df['age']]\n",
    "\n",
    "train_df['deposit'] = labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data:')\n",
    "print('Difference in mean outcomes between unprivileged and privileged groups')\n",
    "print('Had loan:',len(train_df.loc[(train_df.loan == 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.loan == 1])\n",
    "      -len(train_df.loc[(train_df.loan == 0)&(train_df.deposit == 1)])/len(train_df.loc[train_df.loan == 0]))\n",
    "print('Had housing:',len(train_df.loc[(train_df.housing == 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.housing == 1])\n",
    "      -len(train_df.loc[(train_df.housing == 0)&(train_df.deposit == 1)])/len(train_df.loc[train_df.housing == 0]))\n",
    "print('Defaulted:',len(train_df.loc[(train_df.default == 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.default == 1])\n",
    "      -len(train_df.loc[(train_df.default == 0)&(train_df.deposit == 1)])/len(train_df.loc[train_df.default == 0]))\n",
    "print('Middle age:',len(train_df.loc[(train_df.middle_age == 0)&(train_df.deposit == 1)])/len(train_df.loc[train_df.middle_age == 0])\n",
    "      -len(train_df.loc[(train_df.middle_age == 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.middle_age == 1]))\n",
    "print('Married:',len(train_df.loc[(train_df.marital != 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.marital != 1])\n",
    "      -len(train_df.loc[(train_df.marital == 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.marital == 1]))\n",
    "print('No higher education:',len(train_df.loc[(train_df.education != 2)&(train_df.deposit == 1)])/len(train_df.loc[train_df.education != 2])\n",
    "      -len(train_df.loc[(train_df.education == 2)&(train_df.deposit == 1)])/len(train_df.loc[train_df.education == 2]))\n",
    "print('\\n')\n",
    "print('Disparate Impact between unprivileged and privileged groups')\n",
    "print('Had loan:',len(train_df.loc[(train_df.loan == 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.loan == 1])\n",
    "      /(len(train_df.loc[(train_df.loan == 0)&(train_df.deposit == 1)])/len(train_df.loc[train_df.loan == 0])))\n",
    "print('Had housing:',len(train_df.loc[(train_df.housing == 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.housing == 1])\n",
    "      /(len(train_df.loc[(train_df.housing == 0)&(train_df.deposit == 1)])/len(train_df.loc[train_df.housing == 0])))\n",
    "print('Defaulted:',len(train_df.loc[(train_df.default == 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.default == 1])\n",
    "      /(len(train_df.loc[(train_df.default == 0)&(train_df.deposit == 1)])/len(train_df.loc[train_df.default == 0])))\n",
    "print('Middle age:',len(train_df.loc[(train_df.middle_age == 0)&(train_df.deposit == 1)])/len(train_df.loc[train_df.middle_age == 0])\n",
    "      /(len(train_df.loc[(train_df.middle_age == 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.middle_age == 1])))\n",
    "print('Married:',len(train_df.loc[(train_df.marital != 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.marital != 1])\n",
    "      /(len(train_df.loc[(train_df.marital == 1)&(train_df.deposit == 1)])/len(train_df.loc[train_df.marital == 1])))\n",
    "print('No higher education:',len(train_df.loc[(train_df.education != 2)&(train_df.deposit == 1)])/len(train_df.loc[train_df.education != 2])\n",
    "      /(len(train_df.loc[(train_df.education == 2)&(train_df.deposit == 1)])/len(train_df.loc[train_df.education == 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test\n",
    "\n",
    "#create middle age column\n",
    "test_df['middle_age'] = [1 if (30 <= i <= 50) else 0 for i in test_df['age']]\n",
    "\n",
    "test_df['deposit'] = pred_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted Results:')\n",
    "print('Difference in mean outcomes between unprivileged and privileged groups')\n",
    "print('Had loan:',len(test_df.loc[(test_df.loan == 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.loan == 1])\n",
    "      -len(test_df.loc[(test_df.loan == 0)&(test_df.deposit == 1)])/len(test_df.loc[test_df.loan == 0]))\n",
    "print('Had housing:',len(test_df.loc[(test_df.housing == 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.housing == 1])\n",
    "      -len(test_df.loc[(test_df.housing == 0)&(test_df.deposit == 1)])/len(test_df.loc[test_df.housing == 0]))\n",
    "print('Defaulted:',len(test_df.loc[(test_df.default == 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.default == 1])\n",
    "      -len(test_df.loc[(test_df.default == 0)&(test_df.deposit == 1)])/len(test_df.loc[test_df.default == 0]))\n",
    "print('Middle age:',len(test_df.loc[(test_df.middle_age == 0)&(test_df.deposit == 1)])/len(test_df.loc[test_df.middle_age == 0])\n",
    "      -len(test_df.loc[(test_df.middle_age == 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.middle_age == 1]))\n",
    "print('Married:',len(test_df.loc[(test_df.marital != 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.marital != 1])\n",
    "      -len(test_df.loc[(test_df.marital == 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.marital == 1]))\n",
    "print('No higher education:',len(test_df.loc[(test_df.education != 2)&(test_df.deposit == 1)])/len(test_df.loc[test_df.education != 2])\n",
    "      -len(test_df.loc[(test_df.education == 2)&(test_df.deposit == 1)])/len(test_df.loc[test_df.education == 2]))\n",
    "print('\\n')\n",
    "print('Disparate Impact between unprivileged and privileged groups')\n",
    "print('Had loan:',len(test_df.loc[(test_df.loan == 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.loan == 1])\n",
    "      /(len(test_df.loc[(test_df.loan == 0)&(test_df.deposit == 1)])/len(test_df.loc[test_df.loan == 0])))\n",
    "print('Had housing:',len(test_df.loc[(test_df.housing == 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.housing == 1])\n",
    "      /(len(test_df.loc[(test_df.housing == 0)&(test_df.deposit == 1)])/len(test_df.loc[test_df.housing == 0])))\n",
    "print('Defaulted:',len(test_df.loc[(test_df.default == 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.default == 1])\n",
    "      /(len(test_df.loc[(test_df.default == 0)&(test_df.deposit == 1)])/len(test_df.loc[test_df.default == 0])))\n",
    "print('Middle age:',len(test_df.loc[(test_df.middle_age == 0)&(test_df.deposit == 1)])/len(test_df.loc[test_df.middle_age == 0])\n",
    "      /(len(test_df.loc[(test_df.middle_age == 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.middle_age == 1])))\n",
    "print('Married:',len(test_df.loc[(test_df.marital != 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.marital != 1])\n",
    "      /(len(test_df.loc[(test_df.marital == 1)&(test_df.deposit == 1)])/len(test_df.loc[test_df.marital == 1])))\n",
    "print('No higher education:',len(test_df.loc[(test_df.education != 2)&(test_df.deposit == 1)])/len(test_df.loc[test_df.education != 2])\n",
    "      /(len(test_df.loc[(test_df.education == 2)&(test_df.deposit == 1)])/len(test_df.loc[test_df.education == 2])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
